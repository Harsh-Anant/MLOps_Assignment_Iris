{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow --quiet"
      ],
      "metadata": {
        "id": "o-qpTGN-l52n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import os"
      ],
      "metadata": {
        "id": "u7QZlSLHvh5t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load processed data\n",
        "X_train = pd.read_csv('data/X_train.csv')\n",
        "X_test = pd.read_csv('data/X_test.csv')\n",
        "y_train = pd.read_csv('data/y_train.csv').squeeze() # .squeeze() to convert DataFrame to Series\n",
        "y_test = pd.read_csv('data/y_test.csv').squeeze()"
      ],
      "metadata": {
        "id": "G5XLtfD0vtkv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Iris Classification Experiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApS3VMwswBmo",
        "outputId": "7e8970a5-fefc-45b9-81d9-96b953bba2fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/23 10:51:32 INFO mlflow.tracking.fluent: Experiment with name 'Iris Classification Experiment' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='file:///content/mlruns/753176607374753674', creation_time=1753267892189, experiment_id='753176607374753674', last_update_time=1753267892189, lifecycle_stage='active', name='Iris Classification Experiment', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sHTO_GRelo0b"
      },
      "outputs": [],
      "source": [
        "def train_logistic_regression_model_iris():\n",
        "\n",
        "    # Set MLflow tracking URI (optional, defaults to ./mlruns)\n",
        "    # mlflow.set_tracking_uri(\"http://localhost:5000\") # If you run a separate MLflow server\n",
        "\n",
        "    # --- Train Logistic Regression Model ---\n",
        "    with mlflow.start_run(run_name=\"Logistic_Regression_Iris\"):\n",
        "        # Log parameters\n",
        "        solver = \"lbfgs\"\n",
        "        max_iter = 1000\n",
        "        mlflow.log_param(\"model_name\", \"Logistic Regression\")\n",
        "        mlflow.log_param(\"solver\", solver)\n",
        "        mlflow.log_param(\"max_iter\", max_iter)\n",
        "\n",
        "        model_lr = LogisticRegression(solver=solver, max_iter=max_iter)\n",
        "        model_lr.fit(X_train, y_train)\n",
        "        y_pred_lr = model_lr.predict(X_test)\n",
        "\n",
        "        # Log metrics\n",
        "        accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "        precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "        recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "        f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "        mlflow.log_metrics({\n",
        "            \"accuracy\": accuracy_lr,\n",
        "            \"precision\": precision_lr,\n",
        "            \"recall\": recall_lr,\n",
        "            \"f1_score\": f1_lr\n",
        "        })\n",
        "        print(f\"Logistic Regression Accuracy: {accuracy_lr}\")\n",
        "\n",
        "        # Log model\n",
        "        mlflow.sklearn.log_model(model_lr, name=\"logistic_regression_model\", input_example=X_train.head(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_random_forest_classifier_model_iris():\n",
        "  # --- Train RandomForestClassifier Model ---\n",
        "    with mlflow.start_run(run_name=\"RandomForest_Iris\"):\n",
        "        # Log parameters\n",
        "        n_estimators = 100\n",
        "        max_depth = 10\n",
        "        mlflow.log_param(\"model_name\", \"Random Forest\")\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        model_rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model_rf.fit(X_train, y_train)\n",
        "        y_pred_rf = model_rf.predict(X_test)\n",
        "\n",
        "        # Log metrics\n",
        "        accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "        precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "        recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "        f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "        mlflow.log_metrics({\n",
        "            \"accuracy\": accuracy_rf,\n",
        "            \"precision\": precision_rf,\n",
        "            \"recall\": recall_rf,\n",
        "            \"f1_score\": f1_rf\n",
        "        })\n",
        "        print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
        "\n",
        "        # Log model\n",
        "        mlflow.sklearn.log_model(model_rf, name=\"random_forest_model\",input_example=X_train.head(1))\n",
        "\n",
        "    #print(\"\\nMLflow experiments logged. Run 'mlflow ui' in your terminal to view them.\")"
      ],
      "metadata": {
        "id": "jBEej2kPwWYp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_logistic_regression_model_iris()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIuUaw1wtFl",
        "outputId": "4b24cb83-621e-4a27-d799-f21461cc744b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_random_forest_classifier_model_iris()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3u1cxCjw6BW",
        "outputId": "f2819461-294e-413a-b685-d9ae47064f39"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from mlflow.tracking import MlflowClient\n",
        "\n",
        "#client = MlflowClient()\n",
        "run_id = \"145382e126b44b488385f6c21e261a35\"\n",
        "model_uri=f\"/{run_id}/models/m-b1a2dd0b5890495798ae1b1e66cf7f03\"\n",
        "mlflow.register_model(model_uri=model_uri, name=\"IrisSpeciesClassifier\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYld_M6G1Ss-",
        "outputId": "8d14e0ce-e7ba-49af-f3fa-9785b41d0c9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Successfully registered model 'IrisSpeciesClassifier'.\n",
            "Created version '1' of model 'IrisSpeciesClassifier'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ModelVersion: aliases=[], creation_timestamp=1753268943735, current_stage='None', deployment_job_state=None, description=None, last_updated_timestamp=1753268943735, metrics=None, model_id=None, name='IrisSpeciesClassifier', params=None, run_id=None, run_link=None, source='/145382e126b44b488385f6c21e261a35/models/m-b1a2dd0b5890495798ae1b1e66cf7f03', status='READY', status_message=None, tags={}, user_id=None, version=1>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5jNci0o4vJ3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}